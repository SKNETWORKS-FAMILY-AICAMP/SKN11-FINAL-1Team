# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import uuid
import time
import sqlite3
import logging
import re
import numpy as np
from datetime import datetime
from typing import TypedDict, List
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from langchain_core.messages import SystemMessage, HumanMessage
import threading
from contextlib import contextmanager
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger()

# ë¡œë”©
load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# ìƒë‹¨ì— ì¶”ê°€
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "rag_multiformat")


# SQLite DB ì—°ê²°
DATABASE_PATH = os.getenv("DATABASE_PATH", "db.sqlite3")

@contextmanager
def get_db_connection():
    """ì•ˆì „í•œ SQLite ì—°ê²° ê´€ë¦¬"""
    conn = sqlite3.connect(DATABASE_PATH, timeout=30.0, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
        conn.commit()
    except Exception as e:
        conn.rollback()
        raise e
    finally:
        conn.close()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# LangChain êµ¬ì„±
client = QdrantClient(url=QDRANT_URL)
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-4o-mini")

WINDOW_SIZE = 10

class AgentState(TypedDict, total=False):
    question: str
    contexts: List[str]
    answer: str
    reflection: str
    rewritten_question: str
    chat_history: List[str]
    rewrite_count: int
    session_id: str
    summary: str
    evaluation_score: int
    needs_rewrite: bool
    evaluation_details: str
    question_type: str
    user_department_id: int  # ë¶€ì„œ ID ì¶”ê°€

# í’ˆì§ˆ í‰ê°€ ê´€ë¦¬ í´ë˜ìŠ¤
class QualityMetrics:
    def __init__(self):
        self.evaluation_history = []
        self.success_threshold = 14  # 20ì  ë§Œì  ì¤‘ 14ì  ê¸°ì¤€
    
    def update_threshold(self, evaluation_score: int, user_satisfaction: bool):
        """ì‚¬ìš©ì ë§Œì¡±ë„ ê¸°ë°˜ ì„ê³„ê°’ ë™ì  ì¡°ì •"""
        self.evaluation_history.append({
            'score': evaluation_score,
            'satisfied': user_satisfaction,
            'timestamp': datetime.now()
        })
        
        # ìµœê·¼ 50ê°œ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •
        recent_evaluations = self.evaluation_history[-50:]
        
        if len(recent_evaluations) >= 10:
            # ë§Œì¡±ë„ê°€ ë†’ì€ ë‹µë³€ë“¤ì˜ í‰ê·  ì ìˆ˜ ê³„ì‚°
            satisfied_scores = [e['score'] for e in recent_evaluations if e['satisfied']]
            if satisfied_scores:
                self.success_threshold = max(12, min(18, int(np.mean(satisfied_scores)) - 1))
    
    def should_rewrite(self, evaluation_score: int) -> bool:
        return evaluation_score < self.success_threshold

# ì „ì—­ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤
quality_metrics = QualityMetrics()

# ì„¸ì…˜ ë° ë©”ì‹œì§€ DB í•¨ìˆ˜ (ìˆ˜ì •ë¨)
def create_chat_session(user_id: str) -> str:
    """Context Managerë§Œ ì‚¬ìš©í•˜ëŠ” ì„¸ì…˜ ìƒì„±"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        # AutoFieldì´ë¯€ë¡œ session_id ìë™ ìƒì„±
        cursor.execute(
            "INSERT INTO core_chatsession (user_id, summary) VALUES (?, ?)",
            (int(user_id), "ìƒˆ ì±„íŒ… ì„¸ì…˜")
        )
        
        # ìƒì„±ëœ session_id ì¡°íšŒ
        cursor.execute("SELECT last_insert_rowid()")
        session_id = cursor.fetchone()[0]
        
    return str(session_id)

# def save_message(session_id: str, text: str, message_type: str):
#     """Context Managerë§Œ ì‚¬ìš©í•˜ëŠ” ë©”ì‹œì§€ ì €ì¥"""
#     with get_db_connection() as conn:
#         cursor = conn.cursor()
#         cursor.execute(
#             "INSERT INTO core_chatmessage (session_id, create_time, message_text, message_type) VALUES (?, ?, ?, ?)",
#             (int(session_id), datetime.now().isoformat(), text, message_type)
#         )

def save_message(session_id: str, text: str, message_type: str):
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute(
            "INSERT INTO core_chatmessage (session_id, create_time, message_text, message_type, is_active) VALUES (?, ?, ?, ?, ?)",
            (int(session_id), datetime.now().isoformat(), text, message_type, 1)
        )


    # Context Managerê°€ ìë™ìœ¼ë¡œ commit()ê³¼ close() ì²˜ë¦¬

def load_session_history(session_id: str, limit: int = 10) -> List[str]:
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT message_text, message_type
            FROM core_chatmessage
            WHERE session_id = ?
            ORDER BY create_time ASC
        """, (int(session_id),))
        
        messages = cursor.fetchall()

    history = []
    buffer = {}
    for row in messages:
        text, mtype = row[0], row[1]
        if mtype == "user":
            buffer["user"] = text
        elif mtype in ["bot", "chatbot"]:
            buffer["bot"] = text
        if "user" in buffer and "bot" in buffer:
            history.append(f"Q: {buffer['user']}\nA: {buffer['bot']}")
            buffer = {}

    return history[-limit:]


# ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜
def classify_question_type(question: str) -> str:
    """ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•˜ì—¬ ë§ì¶¤í˜• í‰ê°€ ê¸°ì¤€ ì ìš©"""
    question_lower = question.lower()
    
    if any(keyword in question_lower for keyword in ['ì¡°í•­', 'ê·œì •', 'ì¡°ë¡€', 'ë²•ë¥ ', 'ì œ', 'ì¡°']):
        return "regulation"
    elif any(keyword in question_lower for keyword in ['ì ˆì°¨', 'ë°©ë²•', 'ì–´ë–»ê²Œ', 'ì‹ ì²­', 'ì²˜ë¦¬']):
        return "procedure"
    elif any(keyword in question_lower for keyword in ['ì¼ì •', 'ê¸°ê°„', 'ì–¸ì œ', 'ì‹œê°„']):
        return "schedule"
    elif any(keyword in question_lower for keyword in ['ë‹´ë‹¹ì', 'ì—°ë½ì²˜', 'ë¶€ì„œ', 'ëˆ„êµ¬']):
        return "contact"
    else:
        return "general"

# ê°œì„ ëœ ë‹µë³€ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜
def judge_answer_improved(state: AgentState) -> AgentState:
    """êµ¬ì²´ì ì¸ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì„ í‰ê°€"""
    context = "\n---\n".join(state.get("contexts", []))
    question = state['question']
    answer = state['answer']
    question_type = classify_question_type(question)
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ë§ì¶¤ í‰ê°€ ê¸°ì¤€
    if question_type == "regulation":
        evaluation_criteria = """
        1. ì™„ì „ì„±: í•´ë‹¹ ì¡°í•­ ë²ˆí˜¸ì™€ ì œëª©ì´ ëª…ì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: ì¡°í•­ì˜ êµ¬ì²´ì  ë‚´ìš©ì´ ì •í™•íˆ ì¸ìš©ë˜ì—ˆëŠ”ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: ì ìš© ë²”ìœ„ë‚˜ ì˜ˆì™¸ì‚¬í•­ì´ ì„¤ëª…ë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì¡°í•­ì„ ì œì‹œí–ˆëŠ”ê°€? (1-5ì )
        """
    elif question_type == "procedure":
        evaluation_criteria = """
        1. ì™„ì „ì„±: ì ˆì°¨ì˜ ëª¨ë“  ë‹¨ê³„ê°€ ìˆœì„œëŒ€ë¡œ ì„¤ëª…ë˜ì—ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: í•„ìš”í•œ ì„œë¥˜ë‚˜ ì¡°ê±´ì´ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: ë‹´ë‹¹ ë¶€ì„œë‚˜ ì—°ë½ì²˜ ì •ë³´ê°€ í¬í•¨ë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ìì˜ ìƒí™©ì— ë§ëŠ” ì ˆì°¨ë¥¼ ì œì‹œí–ˆëŠ”ê°€? (1-5ì )
        """
    elif question_type == "schedule":
        evaluation_criteria = """
        1. ì™„ì „ì„±: ì •í™•í•œ ì¼ì •ì´ë‚˜ ê¸°ê°„ì´ ì œì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: ì œì‹œëœ ì¼ì •ì´ í˜„ì¬ ê·œì •ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ê¸°ê°„ì´ ëª…ì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¼ì • ì •ë³´ë¥¼ ì œê³µí–ˆëŠ”ê°€? (1-5ì )
        """
    else:
        evaluation_criteria = """
        1. ì™„ì „ì„±: ì§ˆë¬¸ì˜ ëª¨ë“  ë¶€ë¶„ì— ë‹µë³€í–ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: ì œê³µëœ Contextì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì¸ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: êµ¬ì²´ì ì¸ ì •ë³´ì™€ ì˜ˆì‹œê°€ í¬í•¨ë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì¸ê°€? (1-5ì )
        """
    
    # êµ¬ì²´ì ì¸ í‰ê°€ í”„ë¡¬í”„íŠ¸
    evaluation_prompt = f"""
    ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
    
    **í‰ê°€ ê¸°ì¤€ ({question_type} ìœ í˜•):**
    {evaluation_criteria}
    
    **ì§ˆë¬¸:** {question}
    
    **Context:** {context}
    
    **ë‹µë³€:** {answer}
    
    **í‰ê°€ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œì¶œí•˜ì„¸ìš”:**
    ì™„ì „ì„±: Xì  (ì´ìœ : ...)
    ì •í™•ì„±: Xì  (ì´ìœ : ...)
    êµ¬ì²´ì„±: Xì  (ì´ìœ : ...)
    ê´€ë ¨ì„±: Xì  (ì´ìœ : ...)
    ì´ì : Xì  (20ì  ë§Œì )
    ìµœì¢…íŒë‹¨: [ì¶©ë¶„|ë¶€ì¡±]
    ê°œì„ ë°©í–¥: (ë¶€ì¡±í•œ ê²½ìš°ë§Œ) ...
    """
    
    reflection = llm.invoke(evaluation_prompt)
    
    # ì ìˆ˜ ì¶”ì¶œ
    score_match = re.search(r'ì´ì :\s*(\d+)', reflection.content)
    evaluation_score = int(score_match.group(1)) if score_match else 10
    
    # ê°œì„  ë°©í–¥ ì¶”ì¶œ
    improvement_match = re.search(r'ê°œì„ ë°©í–¥:\s*(.+)', reflection.content)
    improvement_direction = improvement_match.group(1) if improvement_match else "ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    # ì¬ì‘ì„± í•„ìš” ì—¬ë¶€ íŒë‹¨
    needs_rewrite = quality_metrics.should_rewrite(evaluation_score)
    
    return {
        **state, 
        "reflection": reflection.content,
        "evaluation_score": evaluation_score,
        "needs_rewrite": needs_rewrite,
        "evaluation_details": improvement_direction,
        "question_type": question_type
    }

# ê°œì„ ëœ ì§ˆë¬¸ ì¬ì‘ì„± í•¨ìˆ˜
def reformulate_question_improved(state: AgentState) -> AgentState:
    """í‰ê°€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì„ ê°œì„ í•˜ì—¬ ì¬ì‘ì„±"""
    question = state.get('question')
    contexts = state.get('contexts', [])
    improvement_direction = state.get('evaluation_details', 'ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
    question_type = state.get('question_type', 'general')
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ Context í‚¤ì›Œë“œ ì¶”ì¶œ
    context_keywords = []
    for context in contexts:
        if '[' in context and ']' in context:
            keyword = context.split('[')[1].split(']')[0]
            context_keywords.append(keyword)
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ì¬ì‘ì„± ê°€ì´ë“œ
    if question_type == "regulation":
        rewrite_guide = """
        1. êµ¬ì²´ì ì¸ ì¡°í•­ ë²ˆí˜¸ë‚˜ ì œëª© ì–¸ê¸‰
        2. í•´ë‹¹ ê·œì •ì˜ ì ìš© ë²”ìœ„ í™•ì¸ ìš”ì²­
        3. ì˜ˆì™¸ì‚¬í•­ì´ë‚˜ íŠ¹ìˆ˜ ì¡°ê±´ í¬í•¨
        4. ê´€ë ¨ í•˜ìœ„ ì¡°í•­ì´ë‚˜ ì‹œí–‰ë ¹ í™•ì¸
        """
    elif question_type == "procedure":
        rewrite_guide = """
        1. ë‹¨ê³„ë³„ ì ˆì°¨ì˜ êµ¬ì²´ì  ìˆœì„œ ìš”ì²­
        2. í•„ìš”í•œ ì„œë¥˜ë‚˜ ì¤€ë¹„ë¬¼ ëª…ì‹œ ìš”êµ¬
        3. ë‹´ë‹¹ ë¶€ì„œë‚˜ ì—°ë½ì²˜ ì •ë³´ í¬í•¨
        4. ì²˜ë¦¬ ê¸°ê°„ì´ë‚˜ ì†Œìš” ì‹œê°„ í™•ì¸
        """
    else:
        rewrite_guide = """
        1. ë” êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ ìš”ì²­
        2. ì‹¤ë¬´ì  ì ìš© ë°©ë²• í¬í•¨
        3. ì˜ˆì™¸ ìƒí™©ì´ë‚˜ ì¶”ê°€ ê³ ë ¤ì‚¬í•­ í™•ì¸
        4. ê´€ë ¨ ë¬¸ì„œë‚˜ ì°¸ê³  ìë£Œ ìš”ì²­
        """
    
    reformulate_prompt = f"""
    ê¸°ì¡´ ì§ˆë¬¸ì„ ë‹¤ìŒ ê°œì„  ë°©í–¥ì— ë”°ë¼ ì¬ì‘ì„±í•˜ì„¸ìš”:
    
    **ê¸°ì¡´ ì§ˆë¬¸:** {question}
    
    **ê°œì„  ë°©í–¥:** {improvement_direction}
    
    **ì§ˆë¬¸ ìœ í˜•:** {question_type}
    
    **ì¬ì‘ì„± ê°€ì´ë“œ:**
    {rewrite_guide}
    
    **ì‚¬ìš© ê°€ëŠ¥í•œ Context í‚¤ì›Œë“œ:**
    {', '.join(context_keywords)}
    
    **ì¬ì‘ì„± ì›ì¹™:**
    - ê¸°ì¡´ ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ëŠ” ìœ ì§€í•˜ë©´ì„œ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
    - í‰ê°€ì—ì„œ ë¶€ì¡±í–ˆë˜ ë¶€ë¶„ì„ ë³´ì™„í•  ìˆ˜ ìˆëŠ” ë°©í–¥ìœ¼ë¡œ ì¬ì‘ì„±
    - ì‚¬ìš© ê°€ëŠ¥í•œ Contextì˜ í‚¤ì›Œë“œë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì„ ìœ ë„
    
    **ì¬ì‘ì„±ëœ ì§ˆë¬¸:**
    """
    
    new_question = llm.invoke(reformulate_prompt).content.strip()
    
    return {
        **state, 
        "rewritten_question": new_question, 
        "rewrite_count": state.get("rewrite_count", 0) + 1
    }

# ê°œì„ ëœ íŒë‹¨ í•¨ìˆ˜
def decide_to_reflect_improved(state: AgentState) -> str:
    """ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì¬ì‘ì„± ì—¬ë¶€ ê²°ì •"""
    if state.get("rewrite_count", 0) >= 2:
        return "summarize"
    
    # í‰ê°€ ì ìˆ˜ ê¸°ë°˜ íŒë‹¨
    if state.get("needs_rewrite", False):
        return "rewrite"
    else:
        return "summarize"

# ì‚¬ìš©ìë³„ í•„í„°ë§ ê²€ìƒ‰ í•¨ìˆ˜
def search_documents_filtered(state: AgentState) -> AgentState:
    """ì‚¬ìš©ì ë¶€ì„œë³„ ë¬¸ì„œ í•„í„°ë§ + ìœ ì‚¬ë„ ê¸°ë°˜ í•„í„°ë§ ì ìš©"""
    query = state.get("rewritten_question") or state["question"]
    user_department_id = state.get("user_department_id")

    query_vec = embeddings.embed_query(query)

    # ğŸ” ë¶€ì„œ í•„í„° ì •ì˜
    if user_department_id:
        search_filter = Filter(
            should=[
                FieldCondition(
                    key="metadata.department_id",
                    match=MatchValue(value=user_department_id)
                ),
                FieldCondition(
                    key="metadata.common_doc",
                    match=MatchValue(value=True)
                )
            ]
        )
    else:
        search_filter = Filter(
            must=[
                FieldCondition(
                    key="metadata.common_doc",
                    match=MatchValue(value=True)
                )
            ]
        )

    # ğŸ” Qdrantì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰
    results = client.search(
        collection_name=COLLECTION_NAME,
        query_vector=query_vec,
        query_filter=search_filter,
        limit=10,
        with_payload=True
    )

    logger.info(f"[ğŸ” Qdrant ê²€ìƒ‰ ê²°ê³¼ ìˆ˜] {len(results)}")

    # âœ… ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§
    threshold = 0.75
    filtered = [r for r in results if r.score >= threshold][:3]

    # fallback: ìœ ì‚¬í•œ ì²­í¬ê°€ ì—†ì„ ê²½ìš° ê°€ì¥ ìƒìœ„ í•˜ë‚˜ë§Œ ì‚¬ìš©
    if not filtered:
        logger.warning("âš ï¸ ìœ ì‚¬í•œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ê°€ì¥ ìœ ì‚¬í•œ 1ê°œ ì²­í¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        filtered = results[:1]

    contexts = []
    for r in filtered:
        title = r.payload.get("metadata", {}).get("title", "ë¬´ì œ")
        text = r.payload.get("text", "")
        file_name = (
            r.payload.get("metadata", {}).get("original_file_name") or
            r.payload.get("metadata", {}).get("file_name", "ì•Œ ìˆ˜ ì—†ìŒ")
        )
        logger.info(f"âœ… í¬í•¨ëœ context: {title} (score: {r.score:.4f})")
        contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")

    return {**state, "contexts": contexts}


# ì„¸ì…˜ ìš”ì•½ í•¨ìˆ˜ (ìˆ˜ì •ë¨)
def summarize_session(state: AgentState) -> AgentState:
    """ë‹¨ì¼ ì—°ê²°ì—ì„œ ëª¨ë“  ì‘ì—… ì²˜ë¦¬"""
    session_id = state.get("session_id")
    if not session_id:
        return state
    
    # í•˜ë‚˜ì˜ ì—°ê²°ì—ì„œ ëª¨ë“  ì‘ì—… ì²˜ë¦¬
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # ë©”ì‹œì§€ ì¡°íšŒ
        cursor.execute("""
            SELECT message_text, message_type
            FROM core_chatmessage
            WHERE session_id = ?
            ORDER BY create_time ASC
        """, (session_id,))
        
        messages = cursor.fetchall()
        
        # íˆìŠ¤í† ë¦¬ ì²˜ë¦¬
        history = []
        buffer = {}
        for row in messages:
            text, mtype = row[0], row[1]
            if mtype == "user":
                buffer["user"] = text
            elif mtype == "bot":
                buffer["bot"] = text
            if "user" in buffer and "bot" in buffer:
                history.append(f"Q: {buffer['user']}\nA: {buffer['bot']}")
                buffer = {}
        
        combined = "\n".join(history[-10:])
        
        # LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±
        messages_for_llm = [
            SystemMessage(content="ë‹¹ì‹ ì€ ê¸°ì—… ë‚´ë¶€ ìƒë‹´ìš© ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì€ í•œ ì‚¬ìš©ìì˜ ìƒë‹´ ê¸°ë¡ì…ë‹ˆë‹¤. í•µì‹¬ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ì¤‘ì‹¬ìœ¼ë¡œ 20ê¸€ì ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."),
            HumanMessage(content=f"ëŒ€í™” ë‚´ìš©:\n{combined}\n\nìš”ì•½:")
        ]
        
        summary = llm.invoke(messages_for_llm).content.strip()
        
        # ê°™ì€ ì—°ê²°ì—ì„œ ìš”ì•½ ì—…ë°ì´íŠ¸
        cursor.execute(
            "UPDATE core_chatsession SET summary = ? WHERE session_id = ?",
            (summary, session_id)
        )
    
    return {**state, "summary": summary}

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ (í•„í„°ë§ìœ¼ë¡œ ë³€ê²½)
def decide_use_rag(state: AgentState) -> AgentState:
    return state

# def get_use_rag_condition(state: AgentState) -> str:
#     question = state["question"]
#     prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì„ ì½ê³ , ì‚¬ë‚´ ë¬¸ì„œë‚˜ ê·œì •ê³¼ ê°™ì€ ì°¸ê³  ë¬¸ì„œê°€ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

# ì§ˆë¬¸: "{question}"

# ë¬¸ì„œê°€ í•„ìš”í•˜ë©´ "use_rag", ì•„ë‹ˆë©´ "skip_rag"ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
    
#     result = llm.invoke(prompt).content.strip().lower()
#     return "use_rag" if "use" in result else "skip_rag"

def get_use_rag_condition(state: AgentState) -> str:
    question = state["question"]

    logger.info("ğŸ”¥ get_use_rag_condition() í•¨ìˆ˜ í˜¸ì¶œë¨!")

    prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ 'íšŒì‚¬ ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸'ì¸ì§€ íŒë‹¨í•˜ëŠ” ì‹¬ì‚¬ê´€ì´ì•¼.

ë‹¤ìŒì˜ ê¸°ì¤€ì— ë”°ë¼ íŒë‹¨í•´:
- íšŒì‚¬ ì •ì±…, ê·œì •, ë©”ë‰´ì–¼, ì œì¶œ ê¸°í•œ, íœ´ê°€ ì œë„, ì‹ ì²­ ì ˆì°¨, ì—…ë¬´ ì²˜ë¦¬ ë°©ì‹ ë“±ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë©´ "use_rag"
- ì¼ë°˜ì ì¸ ì¡ë‹´, ì¼ìƒ ëŒ€í™”, ê°œì¸ì ì¸ ê°ì • ë˜ëŠ” ë„ë¦¬ ì•Œë ¤ì§„ ìƒì‹ ê¸°ë°˜ ì§ˆë¬¸ì´ë©´ "skip_rag"

ì§ˆë¬¸: "{question}"

ë°˜ë“œì‹œ ë”± í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•´: "use_rag" ë˜ëŠ” "skip_rag".
ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.
"""

    result = llm.invoke(prompt).content.strip().lower()
    # âœ… ë¡œê·¸ ì°ê¸°
    logger.info(f"[RAG íŒë‹¨] ì§ˆë¬¸: {question}")
    logger.info(f"[RAG íŒë‹¨] LLM ì‘ë‹µ: {result}")
    logger.info(f"[RAG íŒë‹¨] ê²°ê³¼: {'âœ… use_rag' if 'use_rag' in result else 'âŒ skip_rag'}")
    return "use_rag" if "use_rag" in result else "skip_rag"



def generate_answer(state: AgentState) -> AgentState:
    context = "\n---\n".join(state.get("contexts", []))
    question = state.get("rewritten_question") or state["question"]
    full_history = state.get("chat_history", [])
    recent_history = full_history[-WINDOW_SIZE:]
    history_text = "\n".join(recent_history)
    
    titles = []
    ref_files = set()

    for c in state.get("contexts", []):
        if c.startswith("["):
            lines = c.split("\n")
            if lines:
                titles.append(lines[0].strip("[]"))
            if "(ì¶œì²˜: " in c:
                file_name = c.split("(ì¶œì²˜: ")[1].split(")")[0].strip()
                ref_files.add(file_name)

    ref_titles = ", ".join(titles)
    ref_file_list = ", ".join(sorted(ref_files))  # ì¤‘ë³µ ì œê±°ëœ íŒŒì¼ëª…ë“¤
    
    prompt = f"""
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡:
{history_text}

ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ contextì— ì¶©ì‹¤í•˜ê²Œ ìì„¸íˆ ë‹µë³€í•˜ì„¸ìš”.
â†’ ë°˜ë“œì‹œ í˜•ì‹: "ì œXì¡° ì¡°í•­ëª… ì— ë”°ë¥´ë©´ ..."

ì°¸ê³  ì¡°í•­: {ref_titles}

Context:
{context}

Question: {question}

Answer:"""
    
    response = llm.invoke(prompt)
    answer_text = response.content.strip()

    # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ ì¶”ê°€
    if ref_file_list:
        answer_text += f"\n\nğŸ“„ ì°¸ê³  ë¬¸ì„œ: {ref_file_list}"

    updated_history = full_history + [f"Q: {question}\nA: {answer_text}"]

    return {**state, "answer": answer_text, "chat_history": updated_history}




def direct_answer(state: AgentState) -> AgentState:
    question = state["question"]
    history_text = "\n".join(state.get("chat_history", [])[-WINDOW_SIZE:])
    
    prompt = f"""
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©:
{history_text}

Question: {question}

Answer:"""
    
    response = llm.invoke(prompt)
    updated_history = state.get("chat_history", []) + [f"Q: {question}\nA: {response.content}"]
    
    return {**state, "answer": response.content, "chat_history": updated_history}

# LangGraph ì •ì˜ (ê°œì„ ëœ ë…¸ë“œ ì‚¬ìš©)
builder = StateGraph(AgentState)
builder.add_node("decide", decide_use_rag)
builder.add_node("judge_rag", get_use_rag_condition)
builder.add_node("search", search_documents_filtered)  # í•„í„°ë§ ê²€ìƒ‰ìœ¼ë¡œ ë³€ê²½
builder.add_node("answer", generate_answer)
builder.add_node("judge", judge_answer_improved)  # ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
builder.add_node("rewrite", reformulate_question_improved)  # ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
builder.add_node("direct_answer", direct_answer)
builder.add_node("summarize", summarize_session)

builder.set_entry_point("decide")

builder.add_conditional_edges("decide", get_use_rag_condition, {
    "use_rag": "search", "skip_rag": "direct_answer"
})

builder.add_edge("search", "answer")
builder.add_edge("answer", "judge")

builder.add_conditional_edges("judge", decide_to_reflect_improved, {  # ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
    "summarize": "summarize", "rewrite": "rewrite"
})

builder.add_edge("rewrite", "search")
builder.add_edge("direct_answer", "summarize")
builder.add_edge("summarize", END)

graph = builder.compile()

# ì‹¤í–‰ ì§„ì…ì 
def run_agent(user_id: str):
    session_id = create_chat_session(user_id)
    history = load_session_history(session_id=session_id, limit=10)

    state: AgentState = {
        "chat_history": history,
        "rewrite_count": 0,
        "session_id": session_id
    }

    while True:
        question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if question.lower() == "exit":
            print("\nâœ… ì„¸ì…˜ ì¢…ë£Œ")
            break

        save_message(session_id, question, "user")

        state["question"] = question
        state["rewrite_count"] = 0
        state.pop("rewritten_question", None)

        final = graph.invoke(state)

        answer = final["answer"]
        evaluation_score = final.get("evaluation_score", 0)

        # âœ… RAG ì‚¬ìš© ì—¬ë¶€ íŒë‹¨
        used_rag = bool(final.get("contexts"))  # contextê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ RAG ì‚¬ìš©
        rag_tag = "ğŸ§¾ [RAG ì‚¬ìš©]" if used_rag else "ğŸ’¬ [RAG ë¯¸ì‚¬ìš©]"

        # âœ… ì‚¬ìš©ìì—ê²Œ ì¶œë ¥
        print(f"\n{rag_tag}")
        print(f"\nğŸ§  ë‹µë³€:\n{answer}")
        print(f"\nğŸ“Š í‰ê°€ ì ìˆ˜: {evaluation_score}/20")

        # âœ… ë¡œê·¸ì—ë„ ì €ì¥
        save_message(session_id, f"{rag_tag}\n\n{answer}", "bot")

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["chat_history"] = final.get("chat_history", [])


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    run_agent(user_id="ë¡œê·¸ì¸ëœ-ìœ ì €-id")
