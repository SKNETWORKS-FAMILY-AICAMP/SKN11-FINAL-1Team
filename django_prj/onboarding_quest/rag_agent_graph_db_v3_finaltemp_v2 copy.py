# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import uuid
import time
import psycopg2
import logging
from datetime import datetime
from typing import TypedDict, List
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from qdrant_client import QdrantClient
from langchain_core.messages import SystemMessage, HumanMessage

# ë¡œë”©
load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
COLLECTION_NAME = "rag_multiformat"

# DB ì—°ê²°
conn = psycopg2.connect(
    dbname=os.getenv("DB_NAME"),
    user=os.getenv("DB_USER"),
    password=os.getenv("DB_PASSWORD"),
    host=os.getenv("DB_HOST"),
    port=os.getenv("DB_PORT")
)
cursor = conn.cursor()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# LangChain êµ¬ì„±
client = QdrantClient(url=QDRANT_URL, check_compatibility=False)
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-4o-mini")

WINDOW_SIZE = 3

class AgentState(TypedDict, total=False):
    question: str
    contexts: List[str]
    answer: str
    reflection: str
    rewritten_question: str
    chat_history: List[str]
    rewrite_count: int
    session_id: str
    summary: str

# ì„¸ì…˜ ë° ë©”ì‹œì§€ DB í•¨ìˆ˜
def create_chat_session(user_id: str) -> str:
    session_id = str(uuid.uuid4())
    cursor.execute(
        "INSERT INTO core_chatsession (session_id, user_id, created_at) VALUES (%s, %s, %s)",
        (session_id, user_id, datetime.now())
    )
    conn.commit()
    return session_id

def save_message(session_id: str, text: str, message_type: str):
    cursor.execute(
        "INSERT INTO core_chatmessage (message_id, session_id, create_time, message_text, message_type) VALUES (%s, %s, %s, %s, %s)",
        (str(uuid.uuid4()), session_id, datetime.now(), text, message_type)
    )
    conn.commit()

def load_user_history(user_id: str, limit: int = 10) -> List[str]:
    cursor.execute("""
        SELECT message_text, message_type
        FROM core_chatmessage
        WHERE session_id IN (
            SELECT session_id FROM core_chatsession WHERE user_id = %s
        )
        ORDER BY create_time DESC
        LIMIT %s
    """, (user_id, limit * 2))
    messages = cursor.fetchall()[::-1]

    history = []
    buffer = {}
    for text, mtype in messages:
        if mtype == "user":
            buffer["user"] = text
        elif mtype == "bot":
            buffer["bot"] = text
        if "user" in buffer and "bot" in buffer:
            history.append(f"Q: {buffer['user']}\nA: {buffer['bot']}")
            buffer = {}
    return history[-limit:]

# ì„¸ì…˜ ìš”ì•½ LangGraph ë…¸ë“œ
def summarize_session(state: AgentState) -> AgentState:
    session_id = state.get("session_id")
    if not session_id:
        return state

    cursor.execute("""
        SELECT message_text, message_type
        FROM core_chatmessage
        WHERE session_id = %s
        ORDER BY create_time ASC
    """, (session_id,))
    messages = cursor.fetchall()

    history = []
    buffer = {}
    for text, mtype in messages:
        if mtype == "user":
            buffer["user"] = text
        elif mtype == "bot":
            buffer["bot"] = text
        if "user" in buffer and "bot" in buffer:
            history.append(f"Q: {buffer['user']}\nA: {buffer['bot']}")
            buffer = {}

    combined = "\n".join(history[-10:])

    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ê¸°ì—… ë‚´ë¶€ ìƒë‹´ìš© ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì€ í•œ ì‚¬ìš©ìì˜ ìƒë‹´ ê¸°ë¡ì…ë‹ˆë‹¤. í•µì‹¬ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."),
        HumanMessage(content=f"ëŒ€í™” ë‚´ìš©:\n{combined}\n\nìš”ì•½:")
    ]
    summary = llm.invoke(messages).content.strip()

    cursor.execute(
        "UPDATE core_chatsession SET summary = %s WHERE session_id = %s",
        (summary, session_id)
    )
    conn.commit()

    return {**state, "summary": summary}

# LangGraph ë…¸ë“œ í•¨ìˆ˜
def decide_use_rag(state: AgentState) -> AgentState:
    return state

def get_use_rag_condition(state: AgentState) -> str:
    question = state["question"]
    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì„ ì½ê³ , ì‚¬ë‚´ ë¬¸ì„œë‚˜ ê·œì •ê³¼ ê°™ì€ ì°¸ê³  ë¬¸ì„œê°€ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

ì§ˆë¬¸: \"{question}\"

ë¬¸ì„œê°€ í•„ìš”í•˜ë©´ \"use_rag\", ì•„ë‹ˆë©´ \"skip_rag\"ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
    result = llm.invoke(prompt).content.strip().lower()
    return "use_rag" if "use" in result else "skip_rag"

def search_documents(state: AgentState) -> AgentState:
    query = state.get("rewritten_question") or state["question"]
    query_vec = embeddings.embed_query(query)
    results = client.search(collection_name=COLLECTION_NAME, query_vector=query_vec, limit=3, with_payload=True)
    contexts = []
    for r in results:
        title = r.payload.get("metadata", {}).get("title", "ë¬´ì œ")
        text = r.payload.get("text", "")
        contexts.append(f"[{title}]\n{text}")
    return {**state, "contexts": contexts}

def generate_answer(state: AgentState) -> AgentState:
    context = "\n---\n".join(state.get("contexts", []))
    question = state.get("rewritten_question") or state["question"]
    full_history = state.get("chat_history", [])
    recent_history = full_history[-WINDOW_SIZE:]
    history_text = "\n".join(recent_history)
    titles = [c.split('\n')[0].strip("[]") for c in state.get("contexts", []) if c.startswith("[")]
    ref_titles = ", ".join(titles)
    prompt = f"""
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡:
{history_text}

ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ contextì— ì¶©ì‹¤í•˜ê²Œ ìì„¸íˆ ë‹µë³€í•˜ì„¸ìš”.
â†’ ë°˜ë“œì‹œ í˜•ì‹: \"ì œXì¡° ì¡°í•­ëª… ì— ë”°ë¥´ë©´ ...\"

ì°¸ê³  ì¡°í•­: {ref_titles}

Context:
{context}
Question: {question}
Answer:"""
    response = llm.invoke(prompt)
    updated_history = full_history + [f"Q: {question}\nA: {response.content}"]
    return {**state, "answer": response.content, "chat_history": updated_history}

def direct_answer(state: AgentState) -> AgentState:
    question = state["question"]
    history_text = "\n".join(state.get("chat_history", [])[-WINDOW_SIZE:])
    prompt = f"""
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©:
{history_text}

Question: {question}
Answer:"""
    response = llm.invoke(prompt)
    updated_history = state.get("chat_history", []) + [f"Q: {question}\nA: {response.content}"]
    return {**state, "answer": response.content, "chat_history": updated_history}

def judge_answer(state: AgentState) -> AgentState:
    context = "\n---\n".join(state.get("contexts", []))
    prompt = f"""ì§ˆë¬¸: {state['question']}
Context: {context}
Answer: {state['answer']}
ë‹µë³€ì´ ì¶©ë¶„í•œê°€ìš”? 
- í‰ê°€: [ì¶©ë¶„|ë¶€ì¡±]
- ì´ìœ : ..."""
    reflection = llm.invoke(prompt)
    return {**state, "reflection": reflection.content}

def decide_to_reflect(state: AgentState) -> str:
    if state.get("rewrite_count", 0) >= 2:
        return "summarize"
    return "summarize" if "ì¶©ë¶„" in state.get("reflection", "") else "rewrite"

def reformulate_question(state: AgentState) -> AgentState:
    prompt = f"""ë‹µë³€ì´ ë¶€ì¡±í•˜ë‹¤ë©´, ì§ˆë¬¸ì„ ì¢€ ë” ëª…í™•í•˜ê²Œ ë‹¤ì‹œ ì‘ì„±í•´ì£¼ì„¸ìš”.
ê¸°ì¡´ ì§ˆë¬¸: {state.get('question')}
ë‹µë³€: {state['answer']}
Context: {'---'.join(state.get('contexts', []))}

ìƒˆ ì§ˆë¬¸:"""
    new_q = llm.invoke(prompt).content.strip()
    return {**state, "rewritten_question": new_q, "rewrite_count": state.get("rewrite_count", 0) + 1}

# LangGraph ì •ì˜
builder = StateGraph(AgentState)
builder.add_node("decide", decide_use_rag)
builder.add_node("search", search_documents)
builder.add_node("answer", generate_answer)
builder.add_node("judge", judge_answer)
builder.add_node("rewrite", reformulate_question)
builder.add_node("direct_answer", direct_answer)
builder.add_node("summarize", summarize_session)

builder.set_entry_point("decide")
builder.add_conditional_edges("decide", get_use_rag_condition, {
    "use_rag": "search", "skip_rag": "direct_answer"
})
builder.add_edge("search", "answer")
builder.add_edge("answer", "judge")
builder.add_conditional_edges("judge", decide_to_reflect, {
    "summarize": "summarize", "rewrite": "search"
})
builder.add_edge("rewrite", "search")
builder.add_edge("direct_answer", "summarize")
builder.add_edge("summarize", END)

graph = builder.compile()

# ì‹¤í–‰ ì§„ì…ì 
def run_agent(user_id: str):
    session_id = create_chat_session(user_id)
    history = load_user_history(user_id, limit=5)
    state: AgentState = {
        "chat_history": history,
        "rewrite_count": 0,
        "session_id": session_id
    }

    while True:
        question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if question.lower() == "exit":
            print("\nâœ… ì„¸ì…˜ ì¢…ë£Œ")
            break

        save_message(session_id, question, "user")
        state["question"] = question
        state["rewrite_count"] = 0
        state.pop("rewritten_question", None)

        final = graph.invoke(state)
        answer = final["answer"]
        print(f"\nğŸ§  ë‹µë³€:\n{answer}")
        save_message(session_id, answer, "bot")
        state["chat_history"] = final.get("chat_history", [])

# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    run_agent(user_id="ë¡œê·¸ì¸ëœ-ìœ ì €-id")
