# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import uuid
import time
import psycopg2
from psycopg2.extras import RealDictCursor
import logging
import re
import numpy as np
from datetime import datetime
from typing import TypedDict, List
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from langchain_core.messages import SystemMessage, HumanMessage
import threading
from contextlib import contextmanager
from qdrant_client.http.models import Filter, FieldCondition, MatchValue 
from qdrant_client.models import MatchText

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger()

# ë¡œë”©
load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# ìƒë‹¨ì— ì¶”ê°€
COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "rag_multiformat")

# PostgreSQL DB ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': os.getenv("DB_HOST", "localhost"),
    'port': os.getenv("DB_PORT", "5432"),
    'database': os.getenv("DB_NAME", "onboarding_quest_db"),
    'user': os.getenv("DB_USER", "postgres"),
    'password': os.getenv("DB_PASSWORD", "")
}

@contextmanager
def get_db_connection():
    """ì•ˆì „í•œ PostgreSQL ì—°ê²° ê´€ë¦¬"""
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG, cursor_factory=RealDictCursor)
        conn.autocommit = False
        yield conn
        conn.commit()
    except Exception as e:
        if conn:
            conn.rollback()
        logger.error(f"Database error: {e}")
        raise e
    finally:
        if conn:
            conn.close()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# LangChain êµ¬ì„±
client = QdrantClient(url=QDRANT_URL)
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model="text-embedding-3-large")
# llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-4o-mini")
llm_fast = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-3.5-turbo")
llm_smart = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name="gpt-4o-mini")


WINDOW_SIZE = 10

class AgentState(TypedDict, total=False):
    question: str
    contexts: List[str]
    answer: str
    reflection: str
    rewritten_question: str
    chat_history: List[str]
    rewrite_count: int
    session_id: str
    summary: str
    evaluation_score: int
    needs_rewrite: bool
    evaluation_details: str
    question_type: str
    user_department_id: int  # ë¶€ì„œ ID ì¶”ê°€
    doc_filter: List[str]  # âœ… ì´ ì¤„ ì¶”ê°€

# í’ˆì§ˆ í‰ê°€ ê´€ë¦¬ í´ë˜ìŠ¤
class QualityMetrics:
    def __init__(self):
        self.evaluation_history = []
        self.success_threshold = 14  # 20ì  ë§Œì  ì¤‘ 14ì  ê¸°ì¤€
    
    def update_threshold(self, evaluation_score: int, user_satisfaction: bool):
        """ì‚¬ìš©ì ë§Œì¡±ë„ ê¸°ë°˜ ì„ê³„ê°’ ë™ì  ì¡°ì •"""
        self.evaluation_history.append({
            'score': evaluation_score,
            'satisfied': user_satisfaction,
            'timestamp': datetime.now()
        })
        
        # ìµœê·¼ 50ê°œ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •
        recent_evaluations = self.evaluation_history[-50:]
        
        if len(recent_evaluations) >= 10:
            # ë§Œì¡±ë„ê°€ ë†’ì€ ë‹µë³€ë“¤ì˜ í‰ê·  ì ìˆ˜ ê³„ì‚°
            satisfied_scores = [e['score'] for e in recent_evaluations if e['satisfied']]
            if satisfied_scores:
                self.success_threshold = max(12, min(18, int(np.mean(satisfied_scores)) - 1))
    
    def should_rewrite(self, evaluation_score: int) -> bool:
        return evaluation_score < self.success_threshold

# ì „ì—­ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤
quality_metrics = QualityMetrics()

# ì„¸ì…˜ ë° ë©”ì‹œì§€ DB í•¨ìˆ˜ (PostgreSQL ë²„ì „)
def create_chat_session(user_id: str) -> str:
    """PostgreSQLì„ ì‚¬ìš©í•˜ëŠ” ì„¸ì…˜ ìƒì„±"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        # PostgreSQL SERIAL íƒ€ì…ì´ë¯€ë¡œ session_id ìë™ ìƒì„±
        cursor.execute(
            "INSERT INTO core_chatsession (user_id, summary) VALUES (%s, %s) RETURNING session_id",
            (int(user_id), "ìƒˆ ì±„íŒ… ì„¸ì…˜")
        )
        
        # ìƒì„±ëœ session_id ì¡°íšŒ
        session_id = cursor.fetchone()['session_id']
        
    return str(session_id)


def save_message(session_id: str, text: str, message_type: str):
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute(
            "INSERT INTO core_chatmessage (session_id, create_time, message_text, message_type, is_active) VALUES (%s, %s, %s, %s, %s)",
            (int(session_id), datetime.now(), text, message_type, True)
        )


def load_session_history(session_id: str, limit: int = 10) -> List[str]:
    with get_db_connection() as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT message_text, message_type
            FROM core_chatmessage
            WHERE session_id = %s
            ORDER BY create_time ASC
        """, (int(session_id),))
        
        messages = cursor.fetchall()

    history = []
    buffer = {}
    for row in messages:
        text, mtype = row['message_text'], row['message_type']
        if mtype == "user":
            buffer["user"] = text
        elif mtype in ["bot", "chatbot"]:
            buffer["bot"] = text
        if "user" in buffer and "bot" in buffer:
            history.append(f"Q: {buffer['user']}\nA: {buffer['bot']}")
            buffer = {}

    return history[-limit:]


# ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜
def classify_question_type(question: str) -> str:
    """ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•˜ì—¬ ë§ì¶¤í˜• í‰ê°€ ê¸°ì¤€ ì ìš©"""
    question_lower = question.lower()
    
    if any(keyword in question_lower for keyword in ['ì¡°í•­', 'ê·œì •', 'ì¡°ë¡€', 'ë²•ë¥ ', 'ì œ', 'ì¡°']):
        return "regulation"
    elif any(keyword in question_lower for keyword in ['ì ˆì°¨', 'ë°©ë²•', 'ì–´ë–»ê²Œ', 'ì‹ ì²­', 'ì²˜ë¦¬']):
        return "procedure"
    elif any(keyword in question_lower for keyword in ['ì¼ì •', 'ê¸°ê°„', 'ì–¸ì œ', 'ì‹œê°„']):
        return "schedule"
    elif any(keyword in question_lower for keyword in ['ë‹´ë‹¹ì', 'ì—°ë½ì²˜', 'ë¶€ì„œ', 'ëˆ„êµ¬']):
        return "contact"
    else:
        return "general"

# ê°œì„ ëœ ë‹µë³€ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜
def judge_answer_improved(state: AgentState) -> AgentState:
    start = time.time()
    logger.info("ğŸŸ¢ judge_answer_improved ì‹œì‘")
    logger.info("ğŸ“Š judge_answer_improved ì‹¤í–‰")
    """êµ¬ì²´ì ì¸ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì„ í‰ê°€"""
    context = "\n---\n".join(state.get("contexts", []))
    question = state['question']
    answer = state['answer']
    question_type = classify_question_type(question)
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ë§ì¶¤ í‰ê°€ ê¸°ì¤€
    if question_type == "regulation":
        evaluation_criteria = """
        1. ì™„ì „ì„±: í•´ë‹¹ ì¡°í•­ ë²ˆí˜¸ì™€ ì œëª©ì´ ëª…ì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: ì¡°í•­ì˜ êµ¬ì²´ì  ë‚´ìš©ì´ ì •í™•íˆ ì¸ìš©ë˜ì—ˆëŠ”ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: ì ìš© ë²”ìœ„ë‚˜ ì˜ˆì™¸ì‚¬í•­ì´ ì„¤ëª…ë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì¡°í•­ì„ ì œì‹œí–ˆëŠ”ê°€? (1-5ì )
        """
    elif question_type == "procedure":
        evaluation_criteria = """
        1. ì™„ì „ì„±: ì ˆì°¨ì˜ ëª¨ë“  ë‹¨ê³„ê°€ ìˆœì„œëŒ€ë¡œ ì„¤ëª…ë˜ì—ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: í•„ìš”í•œ ì„œë¥˜ë‚˜ ì¡°ê±´ì´ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: ë‹´ë‹¹ ë¶€ì„œë‚˜ ì—°ë½ì²˜ ì •ë³´ê°€ í¬í•¨ë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ìì˜ ìƒí™©ì— ë§ëŠ” ì ˆì°¨ë¥¼ ì œì‹œí–ˆëŠ”ê°€? (1-5ì )
        """
    elif question_type == "schedule":
        evaluation_criteria = """
        1. ì™„ì „ì„±: ì •í™•í•œ ì¼ì •ì´ë‚˜ ê¸°ê°„ì´ ì œì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: ì œì‹œëœ ì¼ì •ì´ í˜„ì¬ ê·œì •ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ê¸°ê°„ì´ ëª…ì‹œë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¼ì • ì •ë³´ë¥¼ ì œê³µí–ˆëŠ”ê°€? (1-5ì )
        """
    else:
        evaluation_criteria = """
        1. ì™„ì „ì„±: ì§ˆë¬¸ì˜ ëª¨ë“  ë¶€ë¶„ì— ë‹µë³€í–ˆëŠ”ê°€? (1-5ì )
        2. ì •í™•ì„±: ì œê³µëœ Contextì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì¸ê°€? (1-5ì )
        3. êµ¬ì²´ì„±: êµ¬ì²´ì ì¸ ì •ë³´ì™€ ì˜ˆì‹œê°€ í¬í•¨ë˜ì—ˆëŠ”ê°€? (1-5ì )
        4. ê´€ë ¨ì„±: ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‚´ìš©ì¸ê°€? (1-5ì )
        """
    
    # êµ¬ì²´ì ì¸ í‰ê°€ í”„ë¡¬í”„íŠ¸
    evaluation_prompt = f"""
    ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
    
    **í‰ê°€ ê¸°ì¤€ ({question_type} ìœ í˜•):**
    {evaluation_criteria}
    
    **ì§ˆë¬¸:** {question}
    
    **Context:** {context}
    
    **ë‹µë³€:** {answer}
    
    **í‰ê°€ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œì¶œí•˜ì„¸ìš”:**
    ì™„ì „ì„±: Xì  (ì´ìœ : ...)
    ì •í™•ì„±: Xì  (ì´ìœ : ...)
    êµ¬ì²´ì„±: Xì  (ì´ìœ : ...)
    ê´€ë ¨ì„±: Xì  (ì´ìœ : ...)
    ì´ì : Xì  (20ì  ë§Œì )
    ìµœì¢…íŒë‹¨: [ì¶©ë¶„|ë¶€ì¡±]
    ê°œì„ ë°©í–¥: (ë¶€ì¡±í•œ ê²½ìš°ë§Œ) ...
    """
    
    # reflection = llm.invoke(evaluation_prompt)
    reflection = llm_fast.invoke(evaluation_prompt)
    
    # ì ìˆ˜ ì¶”ì¶œ
    score_match = re.search(r'ì´ì :\s*(\d+)', reflection.content)
    evaluation_score = int(score_match.group(1)) if score_match else 10
    
    # ê°œì„  ë°©í–¥ ì¶”ì¶œ
    improvement_match = re.search(r'ê°œì„ ë°©í–¥:\s*(.+)', reflection.content)
    improvement_direction = improvement_match.group(1) if improvement_match else "ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    # ì¬ì‘ì„± í•„ìš” ì—¬ë¶€ íŒë‹¨
    needs_rewrite = quality_metrics.should_rewrite(evaluation_score)
    elapsed = time.time() - start
    logger.info(f"ğŸŸ¢ judge_answer_improved ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")
    
    return {
        **state, 
        "reflection": reflection.content,
        "evaluation_score": evaluation_score,
        "needs_rewrite": needs_rewrite,
        "evaluation_details": improvement_direction,
        "question_type": question_type
    }

# ê°œì„ ëœ ì§ˆë¬¸ ì¬ì‘ì„± í•¨ìˆ˜
def reformulate_question_improved(state: AgentState) -> AgentState:
    start = time.time()
    logger.info("ğŸŸ¢ reformulate_question_improved ì‹œì‘")
    logger.info("âœï¸ reformulate_question_improved ì‹¤í–‰")
    """í‰ê°€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì„ ê°œì„ í•˜ì—¬ ì¬ì‘ì„±"""
    question = state.get('question')
    contexts = state.get('contexts', [])
    improvement_direction = state.get('evaluation_details', 'ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
    question_type = state.get('question_type', 'general')
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ Context í‚¤ì›Œë“œ ì¶”ì¶œ
    context_keywords = []
    for context in contexts:
        if '[' in context and ']' in context:
            keyword = context.split('[')[1].split(']')[0]
            context_keywords.append(keyword)
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ì¬ì‘ì„± ê°€ì´ë“œ
    if question_type == "regulation":
        rewrite_guide = """
        1. êµ¬ì²´ì ì¸ ì¡°í•­ ë²ˆí˜¸ë‚˜ ì œëª© ì–¸ê¸‰
        2. í•´ë‹¹ ê·œì •ì˜ ì ìš© ë²”ìœ„ í™•ì¸ ìš”ì²­
        3. ì˜ˆì™¸ì‚¬í•­ì´ë‚˜ íŠ¹ìˆ˜ ì¡°ê±´ í¬í•¨
        4. ê´€ë ¨ í•˜ìœ„ ì¡°í•­ì´ë‚˜ ì‹œí–‰ë ¹ í™•ì¸
        """
    elif question_type == "procedure":
        rewrite_guide = """
        1. ë‹¨ê³„ë³„ ì ˆì°¨ì˜ êµ¬ì²´ì  ìˆœì„œ ìš”ì²­
        2. í•„ìš”í•œ ì„œë¥˜ë‚˜ ì¤€ë¹„ë¬¼ ëª…ì‹œ ìš”êµ¬
        3. ë‹´ë‹¹ ë¶€ì„œë‚˜ ì—°ë½ì²˜ ì •ë³´ í¬í•¨
        4. ì²˜ë¦¬ ê¸°ê°„ì´ë‚˜ ì†Œìš” ì‹œê°„ í™•ì¸
        """
    else:
        rewrite_guide = """
        1. ë” êµ¬ì²´ì ì¸ ì„¸ë¶€ì‚¬í•­ ìš”ì²­
        2. ì‹¤ë¬´ì  ì ìš© ë°©ë²• í¬í•¨
        3. ì˜ˆì™¸ ìƒí™©ì´ë‚˜ ì¶”ê°€ ê³ ë ¤ì‚¬í•­ í™•ì¸
        4. ê´€ë ¨ ë¬¸ì„œë‚˜ ì°¸ê³  ìë£Œ ìš”ì²­
        """
    
    reformulate_prompt = f"""
    ê¸°ì¡´ ì§ˆë¬¸ì„ ë‹¤ìŒ ê°œì„  ë°©í–¥ì— ë”°ë¼ ì¬ì‘ì„±í•˜ì„¸ìš”:
    
    **ê¸°ì¡´ ì§ˆë¬¸:** {question}
    
    **ê°œì„  ë°©í–¥:** {improvement_direction}
    
    **ì§ˆë¬¸ ìœ í˜•:** {question_type}
    
    **ì¬ì‘ì„± ê°€ì´ë“œ:**
    {rewrite_guide}
    
    **ì‚¬ìš© ê°€ëŠ¥í•œ Context í‚¤ì›Œë“œ:**
    {', '.join(context_keywords)}
    
    **ì¬ì‘ì„± ì›ì¹™:**
    - ê¸°ì¡´ ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ëŠ” ìœ ì§€í•˜ë©´ì„œ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
    - í‰ê°€ì—ì„œ ë¶€ì¡±í–ˆë˜ ë¶€ë¶„ì„ ë³´ì™„í•  ìˆ˜ ìˆëŠ” ë°©í–¥ìœ¼ë¡œ ì¬ì‘ì„±
    - ì‚¬ìš© ê°€ëŠ¥í•œ Contextì˜ í‚¤ì›Œë“œë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì„ ìœ ë„
    
    **ì¬ì‘ì„±ëœ ì§ˆë¬¸:**
    """
    
    new_question = llm_fast.invoke(reformulate_prompt).content.strip()
    elapsed = time.time() - start
    logger.info(f"ğŸŸ¢ reformulate_question_improved ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")
    
    return {
        **state, 
        "rewritten_question": new_question, 
        "rewrite_count": state.get("rewrite_count", 0) + 1
    }

# # ê°œì„ ëœ íŒë‹¨ í•¨ìˆ˜
# def decide_to_reflect_improved(state: AgentState) -> str:
#     """ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì¬ì‘ì„± ì—¬ë¶€ ê²°ì •"""
#     if state.get("rewrite_count", 0) >= 2:
#         return "summarize"
    
#     # í‰ê°€ ì ìˆ˜ ê¸°ë°˜ íŒë‹¨
#     if state.get("needs_rewrite", False):
#         return "rewrite"
#     else:
#         return "summarize"

def decide_to_reflect_improved(state: AgentState) -> str:
    start = time.time()
    logger.info("ğŸŸ¢ decide_to_reflect_improved ì‹œì‘")
    logger.info(f"ğŸ§­ decide_to_reflect_improved ì‹¤í–‰ - score={state.get('evaluation_score')}, count={state.get('rewrite_count')}")
    if state.get("evaluation_score", 20) >= 14:
        return "summarize"  # ì ìˆ˜ ë†’ìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
    if state.get("rewrite_count", 0) >= 1:
        return "summarize"  # ì´ë¯¸ í•œ ë²ˆ ì¬ì‘ì„± í–ˆìœ¼ë©´ ê·¸ë§Œ
    elapsed = time.time() - start
    logger.info(f"ğŸŸ¢ decide_to_reflect_improved ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")
    return "rewrite"  # ê·¸ ì™¸ì—ë§Œ ì¬ì‘ì„±


def search_documents_with_rerank(state: AgentState) -> AgentState:
    import re
    import collections
    start = time.time()
    logger.info("â— search_documents_with_rerank ì‹œì‘")

    query = state.get("rewritten_question") or state["question"]
    user_department_id = state.get("user_department_id")
    query_vec = embeddings.embed_query(query)

    doc_filter = state.get("doc_filter")

    # âœ… ì¡°ê±´ì— ë”°ë¼ ì»¬ë ‰ì…˜ + í•„í„° ì„¤ì •
    combined_results = []

    # âœ… í•­ìƒ ë¶€ì„œ + ê³µí†µ ì»¬ë ‰ì…˜ ìˆœíšŒ (í•„í„° ì—¬ë¶€ëŠ” ë‚´ë¶€ì—ì„œ ë¶„ê¸°)
    collections_to_search = []
    if user_department_id:
        collections_to_search.append(f"rag_{user_department_id}")
    collections_to_search.append("rag_common")

    # ì»¬ë ‰ì…˜ ëŒ€ìƒ ê²°ì •
    collections_to_search = []

    if doc_filter:
        with get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute(
                """
                SELECT DISTINCT original_file_name, department_id, common_doc
                FROM core_docs
                WHERE original_file_name = ANY(%s)
                """,
                (doc_filter,)
            )
            for row in cursor.fetchall():
                if row["common_doc"]:
                    collections_to_search.append("rag_common")
                elif row["department_id"] is not None:
                    collections_to_search.append(f"rag_{row['department_id']}")
    else:
        if user_department_id:
            collections_to_search.append(f"rag_{user_department_id}")
        collections_to_search.append("rag_common")

    collections_to_search = list(set(collections_to_search))  # ì¤‘ë³µ ì œê±°

    # Qdrant ê²€ìƒ‰
    combined_results = []

    for col in collections_to_search:
        try:
            if doc_filter:
                logger.info(f"ğŸ“ í•„í„° ëŒ€ìƒ íŒŒì¼ëª… ëª©ë¡: {doc_filter}")
                logger.info(f"ğŸ“ ì»¬ë ‰ì…˜: {col}")
                query_filter = Filter(
                    must=[
                        FieldCondition(
                            key="metadata.original_file_name",
                            # match=MatchValue(value=filename)
                            match=MatchText(text=filename)  # ë³€ê²½
                        ) for filename in doc_filter
                    ]
                )
            else:
                query_filter = None

            logger.info(f"ğŸ“ ê²€ìƒ‰: {col} | í•„í„°: {doc_filter}")
            result = client.search(
                collection_name=col,
                query_vector=query_vec,
                query_filter=query_filter,
                limit=10,
                with_payload=True
            )
            for r in result:
                logger.info(f"ğŸ“Œ ê²€ìƒ‰ëœ ì²­í¬: {r.payload.get('metadata', {}).get('original_file_name')} / "
                            f"{r.payload.get('metadata', {}).get('hierarchy_path')}")
            combined_results.extend(result)

        except Exception as e:
            logger.warning(f"âš ï¸ Qdrant ê²€ìƒ‰ ì‹¤íŒ¨ - ì»¬ë ‰ì…˜: {col} | ì´ìœ : {e}")


            logger.info(f"ğŸ“ ì •í™• ê²€ìƒ‰ - ì»¬ë ‰ì…˜: {col} | í•„í„°: {doc_filter}")
            result = client.search(
                collection_name=col,
                query_vector=query_vec,
                query_filter=query_filter,
                limit=10,
                with_payload=True
            )
            combined_results.extend(result)

        except Exception as e:
            logger.warning(f"âš ï¸ ì»¬ë ‰ì…˜ '{col}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")




    # if not combined_results:
    #     return {**state, "contexts": []}
        if not combined_results:
            return {**state, "contexts": []}

        # response = llm_smart.invoke(doc_prompt).content.strip()
        # logger.warning(f"ğŸ“¤ GPT rerank ì‘ë‹µ: {response}")

        # selected_idxs = [int(x.strip()) for x in re.findall(r'\d+', response)]
        # valid_idxs = [i for i in selected_idxs if 1 <= i <= len(document_candidates)]

        # if not valid_idxs:
        #     logger.warning(f"âš ï¸ GPT rerankê°€ ë¬¸ì„œ ì„ íƒ ì•ˆ í•¨ â†’ selected_idxs = {selected_idxs}")
        #     logger.warning(f"ğŸ“‰ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(document_candidates)} / ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(combined_results)}")
        #     fallback_contexts = []
        #     combined_top = sorted(combined_results, key=lambda x: x.score, reverse=True)[:3]
        #     for r in combined_top:
        #         meta = r.payload.get("metadata", {})
        #         title = meta.get("title", "ë¬´ì œ")
        #         text = r.payload.get("text", "")
        #         file_name = meta.get("original_file_name", "unknown")
        #         hierarchy_path = meta.get("hierarchy_path")
        #         if hierarchy_path:
        #             fallback_contexts.append(f"[{hierarchy_path} | {title}] (ì¶œì²˜: {file_name})\n{text}")
        #         else:
        #             fallback_contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")
        #     return {**state, "contexts": fallback_contexts}

        # contexts = []
        # for idx in valid_idxs:
        #     chunk = document_candidates[idx - 1]
        #     meta = chunk["metadata"]
        #     title = meta.get("title", "ë¬´ì œ")
        #     text = chunk["text"]
        #     file_name = meta.get("original_file_name", "unknown")
        #     hierarchy_path = meta.get("hierarchy_path")
        #     if hierarchy_path:
        #         contexts.append(f"[{hierarchy_path} | {title}] (ì¶œì²˜: {file_name})\n{text}")
        #     else:
        #         contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")

        # return {**state, "contexts": contexts}



    # í™˜ê²½ ì„¤ì •: ë¬¸ì„œ ë³„ ë¬´ë£Œ
    docs_map = collections.defaultdict(list)
    for r in combined_results:
        file_name = r.payload.get("metadata", {}).get("original_file_name") or r.payload.get("metadata", {}).get("file_name") or "unknown"
        docs_map[file_name].append(r)

    # ë¬¸ì„œ ë‹¨ìœ„ë¡œ representative chunkë¥¼ 2~3ê°œë¡œ ë°œì²´
    document_candidates = []
    for i, (file_name, results) in enumerate(docs_map.items(), 1):
        chunks_text = ""
        for j, r in enumerate(results[:3], 1):
            meta = r.payload.get("metadata", {})
            title = meta.get("title", f"chunk {j}")
            chunk = r.payload.get("text", "")
            hierarchy_path = meta.get("hierarchy_path")
            if hierarchy_path:
                chunks_text += f"- {hierarchy_path} | {title}: {chunk[:200]}...\n"
            else:
                chunks_text += f"- {title}: {chunk[:200]}...\n"
        document_candidates.append((i, file_name, chunks_text.strip(), results))

    doc_prompt = f"""
    ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê´€ë ¨ë  ìˆ˜ ìˆëŠ” ì—¬ëŸ¬ ë¬¸ì„œì…ë‹ˆë‹¤.
    ê° ë¬¸ì„œëŠ” ëŒ€í‘œ ì²­í¬ ì¼ë¶€ë¥¼ ìš”ì•½í•œ ê²ƒì´ë©°, ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê³ ë¥´ì„¸ìš”.

    ì§ˆë¬¸:
    {query}

    ë¬¸ì„œ í›„ë³´:
    """
    for idx, file_name, chunks, _ in document_candidates:
        doc_prompt += f"\në¬¸ì„œ {idx} ({file_name}):\n{chunks}\n"

    doc_prompt += """
    ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ ë²ˆí˜¸ë¥¼ 1ê°œ ë˜ëŠ” 2ê°œ ì„ íƒí•˜ì„¸ìš”.
    ë¬¸ì„œ ë²ˆí˜¸ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: 1 ë˜ëŠ” 1,2)
    ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
    """

    response = llm_smart.invoke(doc_prompt).content.strip()
    logger.warning(f"ğŸ“¤ GPT rerank ì‘ë‹µ: {response}")

    selected_idxs = [int(x.strip()) for x in re.findall(r'\d+', response)]
    valid_idxs = [i for i in selected_idxs if 1 <= i <= len(document_candidates)]

    if not valid_idxs:
        logger.warning(f"âš ï¸ GPT rerankê°€ ë¬¸ì„œ ì„ íƒ ì•ˆ í•¨ â†’ selected_idxs = {selected_idxs}")
        logger.warning(f"ğŸ“‰ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(document_candidates)} / ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(combined_results)}")
        # return {**state, "contexts": []}  # fallback ì œê±°
        return {
            **state,
            "contexts": ["[ì•ˆë‚´] ì„ íƒí•œ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."]
        }


    # if not valid_idxs:
    #     logger.warning(f"âš ï¸ GPT rerankê°€ ë¬¸ì„œ ì„ íƒ ì•ˆ í•¨ â†’ selected_idxs = {selected_idxs}")
    #     logger.warning(f"ğŸ“‰ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(document_candidates)} / ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(combined_results)}")
    #     fallback_contexts = []
    #     combined_top = sorted(combined_results, key=lambda x: x.score, reverse=True)[:3]
    #     for r in combined_top:
    #         meta = r.payload.get("metadata", {})
    #         title = meta.get("title", "ë¬´ì œ")
    #         text = r.payload.get("text", "")
    #         file_name = meta.get("original_file_name", "unknown")
    #         hierarchy_path = meta.get("hierarchy_path")
    #         if hierarchy_path:
    #             fallback_contexts.append(f"[{hierarchy_path} | {title}] (ì¶œì²˜: {file_name})\n{text}")
    #         else:
    #             fallback_contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")
    #     return {**state, "contexts": fallback_contexts}

    contexts = []
    for idx in valid_idxs:
        _, file_name, _, results = document_candidates[idx - 1]
        for r in results[:3]:
            meta = r.payload.get("metadata", {})
            title = meta.get("title", "ë¬´ì œ")
            text = r.payload.get("text", "")
            hierarchy_path = meta.get("hierarchy_path")
            if hierarchy_path:
                last_level = hierarchy_path.split('>')[-1].strip()
                if last_level == title:
                    contexts.append(f"[{hierarchy_path}] (ì¶œì²˜: {file_name})\n{text}")
                else:
                    contexts.append(f"[{hierarchy_path} | {title}] (ì¶œì²˜: {file_name})\n{text}")
            else:
                contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")

    elapsed = time.time() - start
    logger.info(f"â— search_documents_with_rerank ì™„ë£Œ - â± {elapsed:.2f}ì´ˆ")
    return {**state, "contexts": contexts}

    # response = llm_smart.invoke(doc_prompt).content.strip()
    # selected_idxs = [int(x.strip()) for x in re.findall(r'\d+', response)]

    # logger.warning(f"âš ï¸ GPT rerankê°€ ë¬¸ì„œ ì„ íƒ ì•ˆ í•¨ â†’ selected_idxs = {selected_idxs}")
    # logger.warning(f"ğŸ“‰ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(document_candidates)} / ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(combined_results)}")

    # contexts = []
    # for idx in selected_idxs:
    #     if 1 <= idx <= len(document_candidates):
    #         _, file_name, _, results = document_candidates[idx - 1]
    #         for r in results[:3]:
    #             meta = r.payload.get("metadata", {})
    #             title = meta.get("title", "ë¬´ì œ")
    #             text = r.payload.get("text", "")
    #             hierarchy_path = meta.get("hierarchy_path")
    #             if hierarchy_path:
    #                 last_level = hierarchy_path.split('>')[-1].strip()
    #                 if last_level == title:
    #                     contexts.append(f"[{hierarchy_path}] (ì¶œì²˜: {file_name})\n{text}")
    #                 else:
    #                     contexts.append(f"[{hierarchy_path} | {title}] (ì¶œì²˜: {file_name})\n{text}")
    #             else:
    #                 contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")

    # elapsed = time.time() - start
    # logger.info(f"\u25cf search_documents_with_rerank ì™„ë£Œ - \u231a {elapsed:.2f}ì´ˆ")
    # return {**state, "contexts": contexts}



# def search_documents_with_rerank(state: AgentState) -> AgentState:
#     start = time.time()
#     logger.info("ğŸŸ¢ search_documents_with_rerank ì‹œì‘")
#     query = state.get("rewritten_question") or state["question"]
#     user_department_id = state.get("user_department_id")

#     query_vec = embeddings.embed_query(query)

#     collections_to_search = []
#     if user_department_id:
#         collections_to_search.append(f"rag_{user_department_id}")
#     collections_to_search.append("rag_common")

#     combined_results = []

#     for col in collections_to_search:
#         try:
#             logger.info(f"ğŸ“ ì»¬ë ‰ì…˜ ê²€ìƒ‰: {col}")
#             result = client.search(
#                 collection_name=col,
#                 query_vector=query_vec,
#                 query_filter=None,  # ì»¬ë ‰ì…˜ ë³„ë¡œ ë‚˜ë‰˜ë¯€ë¡œ í•„í„° ë¶ˆí•„ìš”
#                 limit=10,
#                 with_payload=True
#             )
#             combined_results.extend(result)
#         except Exception as e:
#             logger.warning(f"âš ï¸ ì»¬ë ‰ì…˜ '{col}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

#     if not combined_results:
#         return {**state, "contexts": []}

#     # GPT rerank í”„ë¡¬í”„íŠ¸ êµ¬ì„±
#     prompt_chunks = ""
#     for i, r in enumerate(combined_results, 1):
#         meta = r.payload.get("metadata", {})
#         title = meta.get("title", f"ì²­í¬ {i}")
#         chunk = r.payload.get("text", "")
#         hierarchy_path = meta.get("hierarchy_path")
#         if hierarchy_path:
#             prompt_chunks += f"\nì²­í¬ {i} ({hierarchy_path} | {title}):\n{chunk}\n"
#         else:
#             prompt_chunks += f"\nì²­í¬ {i} ({title}):\n{chunk}\n"

#     rerank_prompt = f"""
# ë‹¤ìŒ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì²­í¬ë¥¼ 3ê°œ ì´ë‚´ë¡œ ì„ íƒí•´ ì£¼ì„¸ìš”.

# ì§ˆë¬¸:
# {query}

# í›„ë³´ ì²­í¬:
# {prompt_chunks}

# ì„ íƒí•œ ì²­í¬ì˜ ë²ˆí˜¸ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,3,5).
# ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
# """

#     response = llm_fast.invoke(rerank_prompt).content.strip()
#     selected_nums = [int(x.strip()) for x in re.findall(r'\d+', response)]

#     contexts = []
#     for idx in selected_nums:
#         if 1 <= idx <= len(combined_results):
#             r = combined_results[idx - 1]
#             meta = r.payload.get("metadata", {})
#             title = meta.get("title", "ë¬´ì œ")
#             text = r.payload.get("text", "")
#             file_name = meta.get("original_file_name") or meta.get("file_name", "ì•Œ ìˆ˜ ì—†ìŒ")
#             hierarchy_path = meta.get("hierarchy_path")
#             if hierarchy_path:
#                 last_level = hierarchy_path.split('>')[-1].strip()
#                 if last_level == title:
#                     contexts.append(f"[{hierarchy_path}] (ì¶œì²˜: {file_name})\n{text}")
#                 else:
#                     contexts.append(f"[{hierarchy_path} | {title}] (ì¶œì²˜: {file_name})\n{text}")
#             else:
#                 contexts.append(f"[{title}] (ì¶œì²˜: {file_name})\n{text}")

#     elapsed = time.time() - start
#     logger.info(f"ğŸŸ¢ search_documents_with_rerank ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")

#     return {**state, "contexts": contexts}



# ì„¸ì…˜ ìš”ì•½ í•¨ìˆ˜ (PostgreSQL ë²„ì „)
def summarize_session(state: AgentState) -> AgentState:
    start = time.time()
    logger.info("ğŸŸ¢ summarize_session ì‹œì‘")
    logger.info("ğŸ“ summarize_session ì‹¤í–‰")
    """ë‹¨ì¼ ì—°ê²°ì—ì„œ ëª¨ë“  ì‘ì—… ì²˜ë¦¬"""
    session_id = state.get("session_id")
    if not session_id:
        return state
    
    # í•˜ë‚˜ì˜ ì—°ê²°ì—ì„œ ëª¨ë“  ì‘ì—… ì²˜ë¦¬
    with get_db_connection() as conn:
        cursor = conn.cursor()
        
        # ë©”ì‹œì§€ ì¡°íšŒ
        cursor.execute("""
            SELECT message_text, message_type
            FROM core_chatmessage
            WHERE session_id = %s
            ORDER BY create_time ASC
        """, (session_id,))
        
        messages = cursor.fetchall()
        
        # íˆìŠ¤í† ë¦¬ ì²˜ë¦¬
        history = []
        buffer = {}
        for row in messages:
            text, mtype = row['message_text'], row['message_type']
            if mtype == "user":
                buffer["user"] = text
            elif mtype == "bot":
                buffer["bot"] = text
            if "user" in buffer and "bot" in buffer:
                history.append(f"Q: {buffer['user']}\nA: {buffer['bot']}")
                buffer = {}
        
        combined = "\n".join(history[-10:])
        
        # LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±
        messages_for_llm = [
            SystemMessage(content="ë‹¹ì‹ ì€ ê¸°ì—… ë‚´ë¶€ ìƒë‹´ìš© ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì€ í•œ ì‚¬ìš©ìì˜ ìƒë‹´ ê¸°ë¡ì…ë‹ˆë‹¤. í•µì‹¬ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ì¤‘ì‹¬ìœ¼ë¡œ 20ê¸€ì ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”."),
            HumanMessage(content=f"ëŒ€í™” ë‚´ìš©:\n{combined}\n\nìš”ì•½:")
        ]
        
        summary = llm_fast.invoke(messages_for_llm).content.strip()
        
        # ê°™ì€ ì—°ê²°ì—ì„œ ìš”ì•½ ì—…ë°ì´íŠ¸
        cursor.execute(
            "UPDATE core_chatsession SET summary = %s WHERE session_id = %s",
            (summary, session_id)
        )
    elapsed = time.time() - start
    logger.info(f"ğŸŸ¢ summarize_session ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")
    return {**state, "summary": summary}

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ (í•„í„°ë§ìœ¼ë¡œ ë³€ê²½)
def decide_use_rag(state: AgentState) -> AgentState:
    return state


def get_use_rag_condition(state: AgentState) -> str:
    question = state["question"]
    start = time.time()
    logger.info("ğŸŸ¢ get_use_rag_condition ì‹œì‘")
    logger.info("ğŸ”¥ get_use_rag_condition() í•¨ìˆ˜ í˜¸ì¶œë¨!")

    prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ 'íšŒì‚¬ ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸'ì¸ì§€ íŒë‹¨í•˜ëŠ” ì‹¬ì‚¬ê´€ì´ì•¼.

ë‹¤ìŒì˜ ê¸°ì¤€ì— ë”°ë¼ íŒë‹¨í•´:
- íšŒì‚¬ ì •ì±…, ê·œì •, ë©”ë‰´ì–¼, ì œì¶œ ê¸°í•œ, íœ´ê°€ ì œë„, ì‹ ì²­ ì ˆì°¨, ì—…ë¬´ ì²˜ë¦¬ ë°©ì‹ ë“±ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë©´ "use_rag"
- ì¼ë°˜ì ì¸ ì¡ë‹´, ì¼ìƒ ëŒ€í™”, ê°œì¸ì ì¸ ê°ì • ë˜ëŠ” ë„ë¦¬ ì•Œë ¤ì§„ ìƒì‹ ê¸°ë°˜ ì§ˆë¬¸ì´ë©´ "skip_rag"

ì§ˆë¬¸: "{question}"

ë°˜ë“œì‹œ ë”± í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•´: "use_rag" ë˜ëŠ” "skip_rag".
ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆ.
"""

    result = llm_fast.invoke(prompt).content.strip().lower()
    # âœ… ë¡œê·¸ ì°ê¸°
    logger.info(f"[RAG íŒë‹¨] ì§ˆë¬¸: {question}")
    logger.info(f"[RAG íŒë‹¨] LLM ì‘ë‹µ: {result}")
    logger.info(f"[RAG íŒë‹¨] ê²°ê³¼: {'âœ… use_rag' if 'use_rag' in result else 'âŒ skip_rag'}")
    elapsed = time.time() - start
    logger.info(f"ğŸŸ¢ get_use_rag_condition ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")
    return "use_rag" if "use_rag" in result else "skip_rag"



def generate_answer(state: AgentState) -> AgentState:
    start = time.time()
    logger.info("ğŸŸ¢ generate_answer ì‹œì‘")
    logger.info("ğŸ’¬ generate_answer ì‹¤í–‰")
    context = "\n---\n".join(state.get("contexts", []))
    question = state.get("rewritten_question") or state["question"]
    full_history = state.get("chat_history", [])
    recent_history = full_history[-WINDOW_SIZE:]
    history_text = "\n".join(recent_history)
    
    # ì¶œì²˜ ì •ë³´: íŒŒì¼ëª…ë³„ë¡œ (hierarchy_path, title) íŠœí”Œì„ setìœ¼ë¡œ ì§‘ê³„ (ì™„ì „ ì¤‘ë³µ ì œê±°)
    ref_map = {}  # {file_name: set((hierarchy_path, title))}
    for c in state.get("contexts", []):
        if c.startswith("["):
            first_line = c.split("\n")[0]
            if "(ì¶œì²˜: " in first_line:
                file_name = first_line.split("(ì¶œì²˜: ")[-1].split(")")[0].strip()
                left = first_line.split("]")[0].strip("[")
                # hierarchy_pathì™€ title ë¶„ë¦¬
                if "|" in left:
                    hierarchy_path, title = left.split("|", 1)
                    hierarchy_path = hierarchy_path.strip()
                    title = title.strip()
                else:
                    hierarchy_path = ""
                    title = left.strip()
                ref_map.setdefault(file_name, set()).add((hierarchy_path, title))

    # ë‹µë³€ í”„ë¡¬í”„íŠ¸(ì¶œì²˜ ì •ë³´ ì—†ìŒ)
    prompt = f"""
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡:
{history_text}

ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ contextì— ì¶©ì‹¤í•˜ê²Œ, ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ğŸ’¡ ê·œì¹™:

Context:
{context}

ì§ˆë¬¸: {question}

ì •í™•í•˜ê³  ì¹œì ˆí•œ ë‹µë³€:
"""

    # response = llm_smart.invoke(prompt)
    response = llm_smart.invoke(prompt)
    answer_text = response.content.strip()

    # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ ì¶”ê°€ (íŒŒì¼ëª…ë³„ë¡œ ê³„ì¸µ+ì œëª© ë¦¬ìŠ¤íŠ¸, ì™„ì „ ì¤‘ë³µ ì œê±°)
    if ref_map:
        ref_lines = []
        for file_name, hier_set in ref_map.items():
            ref_lines.append(f"ğŸ“„ ì°¸ê³  ë¬¸ì„œ: {file_name}")
            for hierarchy_path, title in sorted(hier_set, key=lambda x: (x[0], x[1])):
                # hierarchy_pathì˜ ë§ˆì§€ë§‰ ê³„ì¸µì´ titleê³¼ ê°™ìœ¼ë©´ titleë§Œ í‘œê¸°
                if hierarchy_path:
                    # ë§ˆì§€ë§‰ ê³„ì¸µ ì¶”ì¶œ (ë§¨ ë’¤ > ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬, ì—†ìœ¼ë©´ ì „ì²´)
                    last_level = hierarchy_path.split('>')[-1].strip()
                    if last_level == title:
                        ref_lines.append(f" - {title}")
                    else:
                        ref_lines.append(f" - {hierarchy_path} | {title}")
                else:
                    ref_lines.append(f" - {title}")
        answer_text += "\n\n" + "\n".join(ref_lines)

    updated_history = full_history + [f"Q: {question}\nA: {answer_text}"]
    elapsed = time.time() - start
    logger.info(f"ğŸŸ¢ generate_answer ì™„ë£Œ - â±ï¸ {elapsed:.2f}ì´ˆ")

    return {**state, "answer": answer_text, "chat_history": updated_history}




def direct_answer(state: AgentState) -> AgentState:
    question = state["question"]
    history_text = "\n".join(state.get("chat_history", [])[-WINDOW_SIZE:])
    
    prompt = f"""
ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©:
{history_text}

Question: {question}

Answer:"""
    
    response = llm_fast.invoke(prompt)
    updated_history = state.get("chat_history", []) + [f"Q: {question}\nA: {response.content}"]
    
    return {**state, "answer": response.content, "chat_history": updated_history}

# LangGraph ì •ì˜ (ê°œì„ ëœ ë…¸ë“œ ì‚¬ìš©)
builder = StateGraph(AgentState)
builder.add_node("decide", decide_use_rag)
builder.add_node("judge_rag", get_use_rag_condition)
# builder.add_node("search", search_documents_filtered)  # í•„í„°ë§ ê²€ìƒ‰ìœ¼ë¡œ ë³€ê²½
builder.add_node("search", search_documents_with_rerank)

builder.add_node("answer", generate_answer)
builder.add_node("judge", judge_answer_improved)  # ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
builder.add_node("rewrite", reformulate_question_improved)  # ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
builder.add_node("direct_answer", direct_answer)
builder.add_node("summarize", summarize_session)

builder.set_entry_point("decide")

builder.add_conditional_edges("decide", get_use_rag_condition, {
    "use_rag": "search", "skip_rag": "direct_answer"
})

builder.add_edge("search", "answer")
builder.add_edge("answer", "judge")

builder.add_conditional_edges("judge", decide_to_reflect_improved, {  # ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
    "summarize": "summarize", "rewrite": "rewrite"
})

builder.add_edge("rewrite", "search")
builder.add_edge("direct_answer", "summarize")
builder.add_edge("summarize", END)

graph = builder.compile()

# ì‹¤í–‰ ì§„ì…ì 
def run_agent(user_id: str):
    session_id = create_chat_session(user_id)
    history = load_session_history(session_id=session_id, limit=10)

    state: AgentState = {
        "chat_history": history,
        "rewrite_count": 0,
        "session_id": session_id
    }

    while True:
        question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if question.lower() == "exit":
            print("\nâœ… ì„¸ì…˜ ì¢…ë£Œ")
            break

        save_message(session_id, question, "user")

        state["question"] = question
        state["rewrite_count"] = 0
        state.pop("rewritten_question", None)

        final = graph.invoke(state)

        answer = final["answer"]
        evaluation_score = final.get("evaluation_score", 0)

        # âœ… RAG ì‚¬ìš© ì—¬ë¶€ íŒë‹¨
        used_rag = bool(final.get("contexts"))  # contextê°€ ë¹„ì–´ìˆì§€ ì•Šìœ¼ë©´ RAG ì‚¬ìš©
        rag_tag = "ğŸ§¾ [RAG ì‚¬ìš©]" if used_rag else "ğŸ’¬ [RAG ë¯¸ì‚¬ìš©]"

        # âœ… ì‚¬ìš©ìì—ê²Œ ì¶œë ¥
        print(f"\n{rag_tag}")
        print(f"\nğŸ§  ë‹µë³€:\n{answer}")
        print(f"\nğŸ“Š í‰ê°€ ì ìˆ˜: {evaluation_score}/20")

        # âœ… ë¡œê·¸ì—ë„ ì €ì¥
        save_message(session_id, f"{rag_tag}\n\n{answer}", "bot")

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state["chat_history"] = final.get("chat_history", [])


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    run_agent(user_id="ë¡œê·¸ì¸ëœ-ìœ ì €-id")
